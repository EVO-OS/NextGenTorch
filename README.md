# NextGenTorch

NextGenTorch is a hybrid neural network framework that integrates TensorFlow, PyTorch, and NextGenJAX. It combines the strengths of these frameworks to provide a versatile tool for developing and training advanced neural network models.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Creating a Model](#creating-a-model)
  - [Training the Model](#training-the-model)
- [Contributing](#contributing)
- [License](#license)

## Features

- **Hybrid Architecture**: Combine TensorFlow and PyTorch models in a single framework.
- **NextGenJAX Integration**: Enhance models with advanced computations using NextGenJAX.
- **Interoperability**: Seamlessly convert data between TensorFlow, PyTorch, and NumPy formats.

## Installation

To install `NextGenTorch`, you need to install TensorFlow, PyTorch, and NextGenJAX. Use the following pip command:

```bash
pip install nextgentorch tensorflow torch nextgenjax
```

## Usage

### Creating a Model

To create a hybrid model using NextGenTorch, you can define TensorFlow and PyTorch components and optionally integrate NextGenJAX for additional functionalities:

```python
import torch
import tensorflow as tf
import nextgenjax as ngj
from nextgentorch import NextGenTorch

# Define TensorFlow component
class TFComponent(tf.keras.Model):
    def __init__(self):
        super(TFComponent, self).__init__()
        self.dense1 = tf.keras.layers.Dense(64, activation='relu')
        self.dense2 = tf.keras.layers.Dense(10)

    def call(self, inputs):
        x = self.dense1(inputs)
        return self.dense2(x)

# Define PyTorch component
class TorchComponent(torch.nn.Module):
    def __init__(self):
        super(TorchComponent, self).__init__()
        self.fc1 = torch.nn.Linear(64, 10)
        self.relu = torch.nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        return x

# Define NextGenJAX function (example)
def jax_enhancement(inputs):
    return ngj.some_jax_function(inputs)

# Initialize models
tf_model = TFComponent()
torch_model = TorchComponent()

# Create NextGenTorch model
model = NextGenTorch(tf_model=tf_model, torch_model=torch_model, jax_function=jax_enhancement)

# Example input (PyTorch tensor)
input_tensor = torch.randn(1, 128)

# Forward pass
output = model.forward(input_tensor)
print(output)
```

### Training the Model

To train your hybrid model, youâ€™ll need to handle the training loop that accommodates both TensorFlow and PyTorch optimizers:

```python
import torch
import tensorflow as tf
from nextgentorch import create_train_state, train_model
from nextgentorch.optimizers import sgd, adam

# Define TensorFlow and PyTorch optimizers
tf_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
torch_optimizer = adam(learning_rate=0.001)

# Create training state
train_state = create_train_state(model, tf_optimizer, torch_optimizer)

# Define training data and loss function
train_data = ...  # Your training data here
loss_fn = ...  # Your loss function here

# Train the model
train_model(train_state, train_data, loss_fn, num_epochs=10)
```

## Contributing

We welcome contributions to the NextGenTorch project! If you have suggestions, bug fixes, or improvements, please follow these guidelines:

1. Fork the repository.
2. Create a new branch for your feature or fix.
3. Commit your changes.
4. Open a pull request describing your modifications.

Please refer to the `CONTRIBUTING.md` file for detailed contribution guidelines.

## License

This project is licensed under the MIT License. See the `LICENSE` file for more details.

---

Feel free to adjust any sections or add additional details specific to your project as needed.
